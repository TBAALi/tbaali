# MachineLearning

[TOC]

## 序言

```shell
本文档为 Machine Leraning 学习中的一些总结记录以及机器学习算法的实现。



Autor: TBAALi
Emil: jiaxx903@foxmail.com
```



## 模型评估与选择



## 线性模型



## K-近邻算法（KNN）

### 工作原理

* 存在一个样本数据集合，也称为训练样本，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据 (最近邻) 的分类标签。一般来说，我们只选择样本数据集中前 k 个最相似的数据，这就是 k-近邻算法中 k 的出处，通常 k 是不大于 20 的整数。最后选择 k 个最相似数据中出现次数最多的分类，最为新数据的分类。

### 优缺点

* 优点：精度高，对异常值不敏感，无数据输入假定。
* 缺点：计算复杂度高，空间复杂度高。
* 适用数据范围：数值型和标称型。

### 归一化

* 处理不同取值范围的特征值，通常将其归一化，将取值范围定到 0 - 1 或 -1 - 1. 下面的公式可以将取值范围定到 0 - 1

  ```c++
  newValue = (oldValue - min) / (max - min)    
  ```

  其中 min 、 max 分别是数据集中的最小特征和最大特征值。



## 决策树

### 工作原理

* 决策树是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个节点代表一种分类结果。
* 监督学习就是给出一堆样本，每个样本都有一组属性和一个分类结果，也就是分类结果已知，那么通过学习这些样本得到一个决策树，这个决策树能够对新的数据给出正确的分类。
* 节点的分裂：一般当一个节点所代表的属性无法给出判断时，则选择将这一节点分成两个节点 (如不是二叉树的情况会分成 n 个子节点)。
* 阈值的确定：选择适当地阈值使得分类错误率最小。
* 比较常见的决策树有 ID3，C4.5 和 CRT，CRT 的分类效果一般优于其他决策树。
* 

### 优缺点

* 优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。
* 缺点：可能会产生过度匹配的问题。
* 适用数据类型：数值和标称型。





## 神经网络



## 支持向量机



## 贝叶斯分类器



## 集成学习



## 聚类



## 降维与度量学习



## 特征选择与稀疏学习



## 计算学习理论



## 半监督学习



## 概率图模型



## 规则学习



## 强化学习

## 

## 后记

1. 数据挖掘十大算法